{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3627,"status":"ok","timestamp":1684407680664,"user":{"displayName":"佐藤太洋","userId":"13036286077109574300"},"user_tz":-540},"id":"-QrsJIci8koH","outputId":"2a44e024-ce6a-491c-bcf4-b9c6f466ada0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/Othercomputers/LAPTOP-3BHDM0TI/windows_research/workspace/research/carbon-steel-classification\n","total 30\n","drwx------ 2 root root 4096 May  8 09:43 app\n","drwx------ 2 root root 4096 May  8 09:52 bin\n","drwx------ 2 root root 4096 May  9 20:26 data\n","drwx------ 5 root root 4096 May 10 06:28 dataset_npz\n","drwx------ 2 root root 4096 May  8 09:16 .git\n","-rw------- 1 root root   48 May  8 09:58 .gitignore\n","-rw------- 1 root root  265 May  8 09:51 Makefile\n","-rw------- 1 root root  358 May  8 09:37 README.md\n","drwx------ 2 root root 4096 May  8 09:38 tmp\n","-rw------- 1 root root 4439 May 18 10:59 TODO.txt\n"]}],"source":["# ドライブのマウント\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 適宜自分のApplicationPATHまで変更\n","APP_PATH = '/content/drive/Othercomputers/LAPTOP-3BHDM0TI/windows_research/workspace/research/carbon-steel-classification'\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import TensorDataset, DataLoader\n","from torch import nn\n","import torch.nn.functional as F\n","from torch import optim\n","\n","from sklearn.model_selection import train_test_split\n","\n","import os\n","import sys\n","import cv2\n","from PIL import Image\n","import pandas as pd\n","\n","\n","os.chdir(APP_PATH)\n","!pwd\n","!ls -al"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"np6tIMs5_Lz8"},"outputs":[],"source":["# ファイルの実行(ノートブック側でランタイムの再接続 or reloadをする)\n","# importで実行するときはファイルのパスを通す必要がある\n","sys.path.append(APP_PATH + '/bin')\n","\n","# setupなどのOSに関するコマンド実行はその定義ファイルをコマンドで実行\n","# 関数などのモジュールはimportで扱えるようにして実行\n","# !python bin/setup.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1341,"status":"ok","timestamp":1684407682002,"user":{"displayName":"佐藤太洋","userId":"13036286077109574300"},"user_tz":-540},"id":"1nLMch089N2C","outputId":"65494638-50c8-4c7e-a90f-1e870e27d5d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["image transpose shape: (3, 960, 960)\n","0 / 290\n","image transpose shape: (3, 960, 960)\n","1 / 290\n","image transpose shape: (3, 960, 960)\n","2 / 290\n","image transpose shape: (3, 960, 960)\n","3 / 290\n","image transpose shape: (3, 960, 960)\n","4 / 290\n","image transpose shape: (3, 960, 960)\n","5 / 290\n","image transpose shape: (3, 960, 960)\n","6 / 290\n","image transpose shape: (3, 960, 960)\n","7 / 290\n","image transpose shape: (3, 960, 960)\n","8 / 290\n","image transpose shape: (3, 960, 960)\n","9 / 290\n","transpose_images dtype: <class 'numpy.ndarray'>\n","transpose_images shape: (10, 3, 960, 960)\n","transpose_images: [[[[ 65  54  47 ... 117 119 115]\n","   [ 74  62  53 ... 110 115 107]\n","   [ 74  88 112 ... 115 113 111]\n","   ...\n","   [ 80  79  89 ...  90  98 134]\n","   [ 84  82 100 ... 239 240 235]\n","   [ 85  84 103 ... 238 236 236]]\n","\n","  [[ 65  54  47 ... 117 119 115]\n","   [ 74  62  53 ... 110 115 107]\n","   [ 74  88 112 ... 115 113 111]\n","   ...\n","   [ 80  79  89 ...  90  98 134]\n","   [ 84  82 100 ... 239 240 235]\n","   [ 85  84 103 ... 238 236 236]]\n","\n","  [[ 65  54  47 ... 117 119 115]\n","   [ 74  62  53 ... 110 115 107]\n","   [ 74  88 112 ... 115 113 111]\n","   ...\n","   [ 80  79  89 ...  90  98 134]\n","   [ 84  82 100 ... 239 240 235]\n","   [ 85  84 103 ... 238 236 236]]]\n","\n","\n"," [[[ 81  82  77 ... 128  99  91]\n","   [ 93  83  86 ... 135 118 112]\n","   [ 90  74  75 ... 138 135 145]\n","   ...\n","   [100 104 120 ... 113 116 122]\n","   [114 115 124 ... 112 121 146]\n","   [119 123 127 ... 116 117 123]]\n","\n","  [[ 81  82  77 ... 128  99  91]\n","   [ 93  83  86 ... 135 118 112]\n","   [ 90  74  75 ... 138 135 145]\n","   ...\n","   [100 104 120 ... 113 116 122]\n","   [114 115 124 ... 112 121 146]\n","   [119 123 127 ... 116 117 123]]\n","\n","  [[ 81  82  77 ... 128  99  91]\n","   [ 93  83  86 ... 135 118 112]\n","   [ 90  74  75 ... 138 135 145]\n","   ...\n","   [100 104 120 ... 113 116 122]\n","   [114 115 124 ... 112 121 146]\n","   [119 123 127 ... 116 117 123]]]\n","\n","\n"," [[[155 158 163 ... 166 166 166]\n","   [156 159 162 ... 166 166 166]\n","   [157 159 162 ... 165 165 165]\n","   ...\n","   [168 170 173 ...  64  82  78]\n","   [168 170 173 ...  68  91  88]\n","   [169 171 173 ...  75 102 100]]\n","\n","  [[155 158 163 ... 166 166 166]\n","   [156 159 162 ... 166 166 166]\n","   [157 159 162 ... 165 165 165]\n","   ...\n","   [168 170 173 ...  64  82  78]\n","   [168 170 173 ...  68  91  88]\n","   [169 171 173 ...  75 102 100]]\n","\n","  [[155 158 163 ... 166 166 166]\n","   [156 159 162 ... 166 166 166]\n","   [157 159 162 ... 165 165 165]\n","   ...\n","   [168 170 173 ...  64  82  78]\n","   [168 170 173 ...  68  91  88]\n","   [169 171 173 ...  75 102 100]]]\n","\n","\n"," ...\n","\n","\n"," [[[204 234 236 ... 243 242 243]\n","   [181 228 234 ... 243 243 243]\n","   [116 218 233 ... 243 242 242]\n","   ...\n","   [236 231 232 ... 226 173 144]\n","   [241 241 241 ... 116 101 118]\n","   [243 242 243 ... 119 110 123]]\n","\n","  [[204 234 236 ... 243 242 243]\n","   [181 228 234 ... 243 243 243]\n","   [116 218 233 ... 243 242 242]\n","   ...\n","   [236 231 232 ... 226 173 144]\n","   [241 241 241 ... 116 101 118]\n","   [243 242 243 ... 119 110 123]]\n","\n","  [[204 234 236 ... 243 242 243]\n","   [181 228 234 ... 243 243 243]\n","   [116 218 233 ... 243 242 242]\n","   ...\n","   [236 231 232 ... 226 173 144]\n","   [241 241 241 ... 116 101 118]\n","   [243 242 243 ... 119 110 123]]]\n","\n","\n"," [[[ 60  50  48 ... 158 158 164]\n","   [ 55  43  38 ... 167 168 153]\n","   [ 69  68  71 ... 160 166 140]\n","   ...\n","   [145 151 158 ... 170 182 187]\n","   [170 156 136 ... 175 179 179]\n","   [153 160 153 ... 173 176 176]]\n","\n","  [[ 60  50  48 ... 158 158 164]\n","   [ 55  43  38 ... 167 168 153]\n","   [ 69  68  71 ... 160 166 140]\n","   ...\n","   [145 151 158 ... 170 182 187]\n","   [170 156 136 ... 175 179 179]\n","   [153 160 153 ... 173 176 176]]\n","\n","  [[ 60  50  48 ... 158 158 164]\n","   [ 55  43  38 ... 167 168 153]\n","   [ 69  68  71 ... 160 166 140]\n","   ...\n","   [145 151 158 ... 170 182 187]\n","   [170 156 136 ... 175 179 179]\n","   [153 160 153 ... 173 176 176]]]\n","\n","\n"," [[[ 81  82  90 ...  87  95 105]\n","   [ 82  82  86 ...  93  92  91]\n","   [ 85  91  98 ... 110 110 100]\n","   ...\n","   [206 200 214 ... 223 219 229]\n","   [216 203 212 ... 184 168 197]\n","   [219 207 213 ... 203 187 187]]\n","\n","  [[ 81  82  90 ...  87  95 105]\n","   [ 82  82  86 ...  93  92  91]\n","   [ 85  91  98 ... 110 110 100]\n","   ...\n","   [206 200 214 ... 223 219 229]\n","   [216 203 212 ... 184 168 197]\n","   [219 207 213 ... 203 187 187]]\n","\n","  [[ 81  82  90 ...  87  95 105]\n","   [ 82  82  86 ...  93  92  91]\n","   [ 85  91  98 ... 110 110 100]\n","   ...\n","   [206 200 214 ... 223 219 229]\n","   [216 203 212 ... 184 168 197]\n","   [219 207 213 ... 203 187 187]]]]\n","transpose_labels dtype: <class 'numpy.ndarray'>\n","transpose_labels shape: (10,)\n","transpose_labels: [5 5 2 3 1 0 2 5 2 4]\n"]}],"source":["# 画像データ(npzのバイナリファイル)の読み込み\n","\n","# 対物レンズ10倍。\n","# 入力サイズ960px\n","# x.1の画像のみのデータセット\n","\n","\n","datasets_npz_x1 = np.load(APP_PATH + '/dataset_npz/x.1_dataset/sc_x10_960_x1.npz')\n","# datasets_npz_x3 = np.load(APP_PATH + '/dataset_npz/x.1_dataset/sc_x10_960_x1.npz')\n","# datasets_npz_all = np.load(APP_PATH + '/dataset_npz/x.1_dataset/sc_x10_960_x1.npz')\n","\n","\n","CATEGORIES=[\"S10C\",\"S15C\",\"S25C\",\"S35C\",\"S45C\",\"S55C\"]\n","\n","\n","# Xはdata, Yはtargetのこと\n","# print(datasets_npz_x1)\n","# print(datasets_npz_x1.files)\n","\n","# データを3次元のtensor([c h w])に変換(1次元と3次元で比較)\n","images = datasets_npz_x1['x']\n","labels = datasets_npz_x1['y']\n","\n","# transpose_images = np.empty(shape=1, dtype=float)\n","# print(\"transpose_images: {}\".format(transpose_images))\n","images_list = []\n","labels_list = []\n","\n","NUM_DATA = 10\n","\n","for i, image in enumerate(images):\n","    # CPUが使い果たされてしまうので200までを使用\n","    if i == NUM_DATA:\n","        break\n","\n","    # 標準化もここで行なう？？\n","    image = Image.fromarray(image)\n","    # print(\"image dtype: {}\".format(type(image)))\n","    image = image.convert(\"RGB\")\n","    # print(\"image mode: {}\".format(image.mode)) # むりやり3チャンネルにしているので表記上はRGBだが実際はL\n","    image = np.asarray(image, np.uint8)\n","    # print(\"image shape: {}\".format(image.shape))\n","    image = np.transpose(image, (2, 0, 1))\n","    print(\"image transpose shape: {}\".format(image.shape))\n","    # transpose_images = np.append(transpose_images, image, axis=0)\n","    images_list.append(image)\n","    labels_list.append(labels[i])\n","    \n","    print(i, '/', len(images))\n","\n","\n","transpose_images = np.array(images_list)\n","transpose_labels = np.array(labels_list)\n","\n","# うまくいっていたら保存\n","print(\"transpose_images dtype: {}\".format(type(transpose_images)))\n","print(\"transpose_images shape: {}\".format(transpose_images.shape))\n","print(\"transpose_images: {}\".format(transpose_images))\n","\n","print(\"transpose_labels dtype: {}\".format(type(transpose_labels)))\n","print(\"transpose_labels shape: {}\".format(transpose_labels.shape))\n","print(\"transpose_labels: {}\".format(transpose_labels))\n","np.savez(APP_PATH, 'data/temp/np_savez', transpose_images, datasets_npz_x1['y'])\n","\n","# image = Image.fromarray(image)\n","# print(\"image dtype: {}\".format(type(image)))\n","# image = image.convert(\"RGB\")\n","# print(\"image mode: {}\".format(image.mode)) # むりやり3チャンネルにしているので表記上はRGBだが実際はL\n","# image = np.asarray(image, np.uint8)\n","# print(\"image shape: {}\".format(image.shape))\n","# image = np.transpose(image, (2, 0, 1))\n","# print(\"image transpose shape: {}\".format(image.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684407682002,"user":{"displayName":"佐藤太洋","userId":"13036286077109574300"},"user_tz":-540},"id":"kJiD_NPdvl9K","outputId":"617e3415-49f9-47a6-9e6c-82123ee36cd7"},"outputs":[{"name":"stdout","output_type":"stream","text":["data.shape: torch.Size([10, 3, 960, 960]) label.shape: torch.Size([10])\n","torch.Size([3, 960, 960]) torch.Size([])\n","tensor([[[ 65.,  54.,  47.,  ..., 117., 119., 115.],\n","         [ 74.,  62.,  53.,  ..., 110., 115., 107.],\n","         [ 74.,  88., 112.,  ..., 115., 113., 111.],\n","         ...,\n","         [ 80.,  79.,  89.,  ...,  90.,  98., 134.],\n","         [ 84.,  82., 100.,  ..., 239., 240., 235.],\n","         [ 85.,  84., 103.,  ..., 238., 236., 236.]],\n","\n","        [[ 65.,  54.,  47.,  ..., 117., 119., 115.],\n","         [ 74.,  62.,  53.,  ..., 110., 115., 107.],\n","         [ 74.,  88., 112.,  ..., 115., 113., 111.],\n","         ...,\n","         [ 80.,  79.,  89.,  ...,  90.,  98., 134.],\n","         [ 84.,  82., 100.,  ..., 239., 240., 235.],\n","         [ 85.,  84., 103.,  ..., 238., 236., 236.]],\n","\n","        [[ 65.,  54.,  47.,  ..., 117., 119., 115.],\n","         [ 74.,  62.,  53.,  ..., 110., 115., 107.],\n","         [ 74.,  88., 112.,  ..., 115., 113., 111.],\n","         ...,\n","         [ 80.,  79.,  89.,  ...,  90.,  98., 134.],\n","         [ 84.,  82., 100.,  ..., 239., 240., 235.],\n","         [ 85.,  84., 103.,  ..., 238., 236., 236.]]])\n","tensor(5)\n"]}],"source":["# transformsなしの自作のデータセット作成\n","\n","data = torch.tensor(transpose_images, dtype=torch.float32)\n","label = torch.tensor(transpose_labels, dtype=torch.int64)\n","\n","print('data.shape:', data.shape, 'label.shape:', label.shape)\n","\n","# Datasetを作成\n","dataset = torch.utils.data.TensorDataset(data, label)\n","\n","X_sample, y_sample = dataset[0]\n","print(X_sample.shape, y_sample.shape)\n","print(X_sample)\n","print(y_sample)\n","\n","\n","\n","# transformsを使ったrailにのったやり方(自作クラスを後に作成する)\n","# https://dreamer-uma.com/pytorch-dataset/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1684407682003,"user":{"displayName":"佐藤太洋","userId":"13036286077109574300"},"user_tz":-540},"id":"Lv-c6LuDvl9L","outputId":"7719039c-d68c-4909-d9cd-a9e203255a3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["num_train: 8\n","num_test: 2\n","train: <torch.utils.data.dataset.Subset object at 0x7f6df6ada320>\n","test: <torch.utils.data.dataset.Subset object at 0x7f6df6adaf50>\n"]}],"source":["# DataLoader ミニバッチ学習\n","# 入力値と目標値をまとめる\n","\n","\n","# 学習データ、検証データ、テストデータに分ける\n","# 各データセットのサンプル数を決定\n","# train : val : test = 60% : 20% : 20%\n","num_train = int(len(dataset) * 0.8)\n","# num_val = int(len(dataset) * 0.2)\n","num_test = int(len(dataset) - num_train)\n","\n","print('num_train:', num_train)\n","# print('num_val:', num_val)\n","print('num_test:', num_test)\n","\n","# ランダムにするらめにシードの固定をした\n","torch.manual_seed(0)\n","# データセットの分割\n","train, test = torch.utils.data.random_split(dataset, [num_train, num_test])\n","print('train:', train)\n","# print('val:', val)\n","print('test:', test)\n","\n","\n","\n","\n","# 一括でデータを作成\n","# train_X, test_X, train_y, test_y = train_test_split(X, y, test_size\n","# =0.8, random_state=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":338,"status":"ok","timestamp":1684407782108,"user":{"displayName":"佐藤太洋","userId":"13036286077109574300"},"user_tz":-540},"id":"a7B85skevl9L","outputId":"e4ba4d20-3acc-4c5e-d0dd-10e44d8d9e54"},"outputs":[{"name":"stdout","output_type":"stream","text":["x: tensor([[[[137., 143., 143.,  ..., 144., 149., 147.],\n","          [136., 141., 147.,  ..., 144., 146., 149.],\n","          [134., 137., 144.,  ..., 144., 144., 146.],\n","          ...,\n","          [150., 149., 151.,  ..., 153., 155., 153.],\n","          [148., 148., 147.,  ..., 149., 151., 151.],\n","          [147., 151., 147.,  ..., 151., 151., 152.]],\n","\n","         [[137., 143., 143.,  ..., 144., 149., 147.],\n","          [136., 141., 147.,  ..., 144., 146., 149.],\n","          [134., 137., 144.,  ..., 144., 144., 146.],\n","          ...,\n","          [150., 149., 151.,  ..., 153., 155., 153.],\n","          [148., 148., 147.,  ..., 149., 151., 151.],\n","          [147., 151., 147.,  ..., 151., 151., 152.]],\n","\n","         [[137., 143., 143.,  ..., 144., 149., 147.],\n","          [136., 141., 147.,  ..., 144., 146., 149.],\n","          [134., 137., 144.,  ..., 144., 144., 146.],\n","          ...,\n","          [150., 149., 151.,  ..., 153., 155., 153.],\n","          [148., 148., 147.,  ..., 149., 151., 151.],\n","          [147., 151., 147.,  ..., 151., 151., 152.]]],\n","\n","\n","        [[[ 60.,  50.,  48.,  ..., 158., 158., 164.],\n","          [ 55.,  43.,  38.,  ..., 167., 168., 153.],\n","          [ 69.,  68.,  71.,  ..., 160., 166., 140.],\n","          ...,\n","          [145., 151., 158.,  ..., 170., 182., 187.],\n","          [170., 156., 136.,  ..., 175., 179., 179.],\n","          [153., 160., 153.,  ..., 173., 176., 176.]],\n","\n","         [[ 60.,  50.,  48.,  ..., 158., 158., 164.],\n","          [ 55.,  43.,  38.,  ..., 167., 168., 153.],\n","          [ 69.,  68.,  71.,  ..., 160., 166., 140.],\n","          ...,\n","          [145., 151., 158.,  ..., 170., 182., 187.],\n","          [170., 156., 136.,  ..., 175., 179., 179.],\n","          [153., 160., 153.,  ..., 173., 176., 176.]],\n","\n","         [[ 60.,  50.,  48.,  ..., 158., 158., 164.],\n","          [ 55.,  43.,  38.,  ..., 167., 168., 153.],\n","          [ 69.,  68.,  71.,  ..., 160., 166., 140.],\n","          ...,\n","          [145., 151., 158.,  ..., 170., 182., 187.],\n","          [170., 156., 136.,  ..., 175., 179., 179.],\n","          [153., 160., 153.,  ..., 173., 176., 176.]]]])\n","t: tensor([1, 2])\n"]}],"source":["# ミニバッチ学習\n","\n","# バッチサイズの定義(目安は全データの1/10だが正解がない)\n","batch_size = 2\n","train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True, drop_last=True)\n","# val_loader = torch.utils.data.DataLoader(val, batch_size)\n","test_loader = torch.utils.data.DataLoader(test, batch_size)\n","\n","# 1つ目のバッチサイズに分割したデータを確認\n","x, t = next(iter(train_loader))\n","\n","print('x:', x)\n","print('t:', t)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10247,"status":"ok","timestamp":1684407798660,"user":{"displayName":"佐藤太洋","userId":"13036286077109574300"},"user_tz":-540},"id":"lw8crVe2vl9L","outputId":"074a09c4-7192-47e1-f259-1de80beca1d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["x shape: torch.Size([3625216])\n","Device: cuda\n","CNN(\n","  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (maxpool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (l1): Linear(in_features=3625216, out_features=128, bias=True)\n","  (l2): Linear(in_features=128, out_features=6, bias=True)\n","  (relu): ReLU(inplace=True)\n",")\n"]}],"source":["# 2.3 ニューラルネットワークの定義\n","\n","num_classes = 6    # CIFAR10のクラスの数を指定\n","\n","# class AlexNet(nn.Module):\n","#     def __init__(self, num_classes=num_classes):\n","#         super(AlexNet, self).__init__()\n","#         self.features = nn.Sequential(\n","#             nn.Conv2d(3, 64, kernel_size=7, padding=2),     # 畳み込み層\n","#             nn.ReLU(inplace=True),                          # 活性化関数\n","#             nn.MaxPool2d(kernel_size=2),                    # プーリング層\n","#             nn.Conv2d(64, 192, kernel_size=5, padding=2),\n","#             nn.ReLU(inplace=True),\n","#             nn.MaxPool2d(kernel_size=2),\n","#             nn.Conv2d(192, 384, kernel_size=3, padding=1),\n","#             nn.ReLU(inplace=True),\n","#             nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","#             nn.ReLU(inplace=True),\n","#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","#             nn.ReLU(inplace=True),\n","#             nn.MaxPool2d(kernel_size=2),\n","#         )\n","#         self.classifier = nn.Sequential(\n","#             nn.Dropout(),                   # ドロップアウト層\n","#             nn.Linear(256 * 3* 3, 4096),\n","#             nn.ReLU(inplace=True),\n","#             nn.Dropout(),\n","#             nn.Linear(4096, 4096),\n","#             nn.ReLU(inplace=True),\n","#             nn.Linear(4096, num_classes),\n","#         )\n","\n","#     # 順伝搬を定義\n","#     def forward(self, x):\n","#         x = self.features(x)                # 画像特徴量抽出パート\n","#         x = x.view(x.size(0), 256 * 3 * 3)  # 3次元から1次元に変えて全結合層へ\n","#         x = self.classifier(x)              # 画像分類パート\n","#         return x\n","\n","n_input = 32 * 32 * 3 # 全結合するために使用する\n","n_output = 6\n","# 中間層のノード数(何でもよい：調べる必要あり)\n","n_hidden = 128\n","\n","\n","# https://www.youtube.com/watch?v=6roIEgXy7wA\n","class CNN(nn.Module):\n","    def __init__(self, n_output, n_hidden):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3)\n","        self.conv2 = nn.Conv2d(32, 32, 3)\n","        self.maxpool = nn.MaxPool2d((2, 2))\n","        # self.flatten = nn.Flatten()\n","        self.flatten = nn.Flatten()\n","        self.l1 = nn.Linear(3625216, n_hidden)\n","        self.l2 = nn.Linear(n_hidden, n_output)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    # 順伝搬を定義\n","    def forward(self, x):\n","        x = self.maxpool(self.relu(self.conv1(x)))\n","        x = self.maxpool(self.relu(self.conv2(x)))\n","        x = torch.flatten(x)\n","        x = self.leru(self.l1(x))\n","        x = self.l2(x)\n","        return x\n","\n","\n","\n","\n","# flattenに入れる前の入力画像(特徴MAP)のサイズ確認\n","conv1 = nn.Conv2d(3, 32, 3)\n","conv2 = nn.Conv2d(32, 32, 3)\n","maxpool = nn.MaxPool2d((2, 2))\n","relu = nn.ReLU(inplace=True)\n","\n","x = maxpool(relu(conv1(x)))\n","x = maxpool(relu(conv2(x)))\n","x = torch.flatten(x)\n","\n","print(\"x shape: {}\".format(x.shape))\n","\n","\n","\n","\n","# ネットワークのロード\n","# CPUとGPUのどちらを使うかを指定\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# net = AlexNet().to(device)\n","print(\"Device: {}\".format(device))\n","net = CNN(n_output, n_hidden).to(device)\n","print(net)\n","# デバイスの確認"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R868b0zHvl9L"},"outputs":[],"source":["# 2.4 損失関数と最適化関数の定義\n","\n","# 損失関数の定義\n","criterion = nn.CrossEntropyLoss()\n","\n","# 活性化関数の定義(最適化アルゴリズムの設定(確率的勾降下法))\n","lr = 0.01\n","optimizer = optim.Adam(net.parameters())\n","# optimizer = optim.SGD(net.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"executionInfo":{"elapsed":7073,"status":"error","timestamp":1684407833807,"user":{"displayName":"佐藤太洋","userId":"13036286077109574300"},"user_tz":-540},"id":"Mk4X6bEQemHX","outputId":"c6cf6302-8d37-4fc8-fb4f-71fbc94b2043"},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------------------\n","Epoch: 1/10\n"]},{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-3760d0af56ac>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# データを入力して予測値を計算(順伝播)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0my_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# 損失(誤差)を計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-9345f2ade595>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'CNN' object has no attribute 'leru'"]}],"source":["# 2.5 学習\n","\n","# 損失と正解率を保持するリストを作成\n","train_loss_list = []        # 学習損失\n","train_accuracy_list = []    # 学習データの正答率\n","test_loss_list = []         # 評価損失\n","test_accuracy_list = []     # テストデータの正答率\n","\n","# 学習(エポック)の実行\n","epoch = 10\n","for i in range(epoch):\n","    # エポックの進行状況を表示\n","    print(\"-------------------------------\")\n","    print(\"Epoch: {}/{}\".format(i+1, epoch))\n","    \n","    # 損失と正解率の初期化\n","    train_loss = 0      # 学習損失\n","    train_accuracy = 0  # 学習データの正答率\n","    test_loss = 0       # 評価損失\n","    test_accuracy = 0   # テストデータの正答率\n","    \n","    # ---------学習パート--------- #\n","    # ニューラルネットワークを学習モードに設定\n","    net.train()\n","    # ミニバッチごとにデータをロードし学習\n","    for images, labels in train_loader:\n","        # GPUにTensorを転送\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # 勾配を初期化\n","        optimizer.zero_grad()\n","        # データを入力して予測値を計算(順伝播)\n","        y_pred_prob = net(images)\n","        # 損失(誤差)を計算\n","        loss = criterion(y_pred_prob, labels)\n","        # 勾配の計算(逆伝搬)\n","        loss.backward()\n","        # パラメータ(重み)の更新\n","        optimizer.step()\n","        \n","        # ミニバッチごとの損失を蓄積\n","        train_loss += loss.item()\n","        \n","        # 予測したラベルを予測確率y_pred_probから計算\n","        y_pred_labels = torch.max(y_pred_prob, 1)[1]\n","        # ミニバッチごとに正解したラベル数をカウント\n","        train_accuracy += torch.sum(y_pred_labels == labels).item() / len(labels)\n","    \n","    # エポックごとの損失と正解率を計算(ミニバッチの平均の損失と正解率を計算)\n","    epoch_train_loss = train_loss / len(train_loader)\n","    epoch_train_accuracy = train_accuracy / len(train_loader)\n","    # ---------学習パートはここまで--------- #\n","    \n","    # ---------評価パート--------- #\n","    # ニューラルネットワークを評価モードに設定\n","    net.eval()\n","    # 評価時の計算で自動微分機能をオフにする\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            # GPUにTensorを転送\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            # データを入力して予測値を計算(順伝播)\n","            y_pred_prob = net(images)\n","            # 損失(誤差)を計算\n","            loss = criterion(y_pred_prob, labels)\n","            # ミニバッチごとの損失を蓄積\n","            test_loss += loss.item()\n","            \n","            # 予測したラベルを予測確率y_pred_probから計算\n","            y_pred_labels = torch.max(y_pred_prob, 1)[1]\n","            # ミニバッチごとに正解したラベル数をカウント\n","            test_accuracy += torch.sum(y_pred_labels == labels).item() / len(labels)\n","        \n","    # エポックごとの損失と正解率を計算(ミニバッチの平均の損失と正解率を計算)\n","    epoch_test_loss = test_loss / len(test_loader)\n","    epoch_test_accuracy = test_accuracy / len(test_loader)\n","    # ---------評価パートはここまで--------- #\n","\n","    # エポックごとに損失と正解率を表示\n","    print(\"Train_Loss: {:.4f}, Train_Accuracy: {:.4f}\".format(epoch_train_loss, epoch_train_accuracy))\n","    print(\"Test_Loss: {:.4f}, Test_Accuracy: {:.4f}\".format(epoch_test_loss, epoch_test_accuracy))\n","\n","    # 損失と正解率をリスト化して保存\n","    train_loss_list.append(epoch_train_loss)\n","    train_accuracy_list.append(epoch_train_accuracy)\n","    test_loss_list.append(epoch_test_loss)\n","    test_accuracy_list.append(epoch_test_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WiN--Ax7emHX"},"outputs":[],"source":["# 2.6 結果の可視化\n","\n","# 損失\n","plt.figure()\n","plt.title('Train and Test Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.plot(range(1, epoch+1), train_loss_list, color='blue', linestyle='-', label='Train_Loss')\n","plt.plot(range(1, epoch+1), test_loss_list, color='red', linestyle='--', label='Test_Loss')\n","plt.legend()    # 凡例\n","\n","# 正解率\n","plt.figure()\n","plt.title('Train and Test Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.plot(range(1, epoch+1), train_accuracy_list, color='blue', linestyle='-', label='Train_Accuracy')\n","plt.plot(range(1, epoch+1), test_accuracy_list, color='red', linestyle='--', label='Test_Accuracy')\n","plt.legend()    # 凡例\n","\n","# 表示\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"va1ja350emHY"},"outputs":[],"source":["# 分類した画像を確認\n","# CIFAR10のクラス\n","# classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  # CIFAR10のクラス\n","CATEGORIES=[\"S10C\",\"S15C\",\"S25C\",\"S35C\",\"S45C\",\"S55C\"]\n","\n","\n","# ニューラルネットワークを評価モードに設定\n","net.eval()\n","# 評価時の計算で自動微分機能をオフにする\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        # GPUにTensorを転送\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        # データを入力して予測値を計算(順伝播)\n","        y_pred_prob = net(images)\n","        # 予測したラベルを予測確率y_pred_probから計算\n","        y_pred_labels = torch.max(y_pred_prob, 1)[1]\n","        \n","        for i in range(9):\n","            image = images[i] / 2 + 0.5\n","            image = image.to('cpu').numpy()\n","            plt.subplot(3, 3, i+1)\n","            # matplotlibでは(縦, 横, チャネル)の順\n","            plt.imshow(np.transpose(image, (1, 2, 0)))\n","            plt.title(CATEGORIES[labels[i]])\n","            plt.title(\"{} ({})\".format(CATEGORIES[y_pred_labels[i].item()], CATEGORIES[labels[i].item()]), color=('green' if y_pred_labels[i] == labels[i] else 'red'))\n","            plt.axis('off')\n","        plt.show()\n","        break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84ezOFPzemHY"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}