{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3627,
     "status": "ok",
     "timestamp": 1684407680664,
     "user": {
      "displayName": "佐藤太洋",
      "userId": "13036286077109574300"
     },
     "user_tz": -540
    },
    "id": "-QrsJIci8koH",
    "outputId": "2a44e024-ce6a-491c-bcf4-b9c6f466ada0"
   },
   "outputs": [],
   "source": [
    "# standard modules\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pdb\n",
    "\n",
    "# myself\n",
    "from config import setting\n",
    "from module import const\n",
    "from module import machine_learning_model  # AlexNet, get_input_size_into_FLATTEN\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from IPython.display import display\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "const.CLASSES = (\"S10C\", \"S15C\", \"S25C\", \"S35C\", \"S45C\", \"S55C\")\n",
    "const.NUM_CLASS = 6\n",
    "\n",
    "const.IMG_HEIGHT = 256\n",
    "const.IMG_WIDTH = 256\n",
    "\n",
    "# バッチサイズ(目安は全データの1/10だが正解なし)\n",
    "# const.BATCH_SIZE = 2\n",
    "# const.BATCH_SIZE = 6\n",
    "# const.BATCH_SIZE = 18\n",
    "const.BATCH_SIZE = 24\n",
    "\n",
    "# const.NUM_EPOCHS = 60\n",
    "const.NUM_EPOCHS =5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1341,
     "status": "ok",
     "timestamp": 1684407682002,
     "user": {
      "displayName": "佐藤太洋",
      "userId": "13036286077109574300"
     },
     "user_tz": -540
    },
    "id": "1nLMch089N2C",
    "outputId": "65494638-50c8-4c7e-a90f-1e870e27d5d6"
   },
   "outputs": [],
   "source": [
    "x10_960_x1_datasets = np.load(const.DATASET_PATH)\n",
    "\n",
    "# データを3次元のtensor([c h w])に変換(1次元と3次元で比較)\n",
    "images = x10_960_x1_datasets[\"x\"]\n",
    "labels = x10_960_x1_datasets[\"y\"]\n",
    "\n",
    "images_list = []\n",
    "labels_list = []\n",
    "\n",
    "# 正規化手法定義 MinMaxScaler(0<=data<=1)\n",
    "mmscaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    print(f\"image: \")\n",
    "    print(image)\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    image = image.resize((const.IMG_HEIGHT, const.IMG_WIDTH))\n",
    "\n",
    "    # print(\"image mode: {}\".format(image.mode)) # むりやり3チャンネルにしているので表記上はRGBだが実際はL\n",
    "    # PIL前に正規化をするとバグる\n",
    "    image = np.asarray(image, np.float32)\n",
    "\n",
    "    # 正規化\n",
    "    # 次元が2以上なので使えない\n",
    "    # image = mmscaler.fit_transform(image)\n",
    "    image = image.astype(float) / 255.0\n",
    "\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    images_list.append(image)\n",
    "    labels_list.append(labels[i])\n",
    "\n",
    "    print(i, \"/\", len(images))\n",
    "\n",
    "\n",
    "transpose_images = np.array(images_list)\n",
    "transpose_labels = np.array(labels_list)\n",
    "\n",
    "print(\"transpose_images dtype: {}\".format(type(transpose_images)))\n",
    "print(\"transpose_images shape: {}\".format(transpose_images.shape))\n",
    "print(\"transpose_images: {}\".format(transpose_images))\n",
    "\n",
    "print(\"transpose_labels dtype: {}\".format(type(transpose_labels)))\n",
    "print(\"transpose_labels shape: {}\".format(transpose_labels.shape))\n",
    "print(\"transpose_labels: {}\".format(transpose_labels))\n",
    "np.savez(\n",
    "    const.APP_PATH, \"data/temp/np_savez\", transpose_images, x10_960_x1_datasets[\"y\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684407682002,
     "user": {
      "displayName": "佐藤太洋",
      "userId": "13036286077109574300"
     },
     "user_tz": -540
    },
    "id": "kJiD_NPdvl9K",
    "outputId": "617e3415-49f9-47a6-9e6c-82123ee36cd7"
   },
   "outputs": [],
   "source": [
    "# transformsなしの自作のデータセット作成\n",
    "data = torch.tensor(transpose_images, dtype=torch.float32)\n",
    "label = torch.tensor(transpose_labels, dtype=torch.int64)\n",
    "\n",
    "print(\"data.shape:\", data.shape, \"label.shape:\", label.shape)\n",
    "\n",
    "# Datasetを作成\n",
    "dataset = torch.utils.data.TensorDataset(data, label)\n",
    "\n",
    "X_sample, y_sample = dataset[0]\n",
    "print(X_sample.shape, y_sample.shape)\n",
    "print(X_sample)\n",
    "print(y_sample)\n",
    "\n",
    "\n",
    "# NOTE: transformsを使ったrailにのったやり方(自作クラスを後に作成する)\n",
    "# https://dreamer-uma.com/pytorch-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1684407682003,
     "user": {
      "displayName": "佐藤太洋",
      "userId": "13036286077109574300"
     },
     "user_tz": -540
    },
    "id": "Lv-c6LuDvl9L",
    "outputId": "7719039c-d68c-4909-d9cd-a9e203255a3b"
   },
   "outputs": [],
   "source": [
    "# DataLoader ミニバッチ学習\n",
    "# 入力値と目標値をまとめる\n",
    "\n",
    "\n",
    "# 学習データ、検証データ、テストデータに分ける\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : test = 60% : 20%\n",
    "num_train = int(len(dataset) * 0.8)\n",
    "num_test = int(len(dataset) - num_train)\n",
    "\n",
    "print(\"num_train:\", num_train)\n",
    "print(\"num_test:\", num_test)\n",
    "\n",
    "# ランダムにするらめにシードの固定をした\n",
    "# torch.manual_seed(0)\n",
    "# データセットの分割\n",
    "train, test = torch.utils.data.random_split(dataset, [num_train, num_test])\n",
    "print(\"train:\", train)\n",
    "print(\"test:\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1684407782108,
     "user": {
      "displayName": "佐藤太洋",
      "userId": "13036286077109574300"
     },
     "user_tz": -540
    },
    "id": "a7B85skevl9L",
    "outputId": "e4ba4d20-3acc-4c5e-d0dd-10e44d8d9e54"
   },
   "outputs": [],
   "source": [
    "# ミニバッチ学習\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train, const.BATCH_SIZE, shuffle=True, drop_last=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test, const.BATCH_SIZE)\n",
    "\n",
    "sample_x, sample_t = next(iter(train_loader))\n",
    "\n",
    "print(\"x:\", sample_x)\n",
    "print(\"t:\", sample_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10247,
     "status": "ok",
     "timestamp": 1684407798660,
     "user": {
      "displayName": "佐藤太洋",
      "userId": "13036286077109574300"
     },
     "user_tz": -540
    },
    "id": "lw8crVe2vl9L",
    "outputId": "074a09c4-7192-47e1-f259-1de80beca1d9"
   },
   "outputs": [],
   "source": [
    "# 2.3 ニューラルネットワークの定義\n",
    "\n",
    "n_output = const.NUM_CLASS\n",
    "# 中間層のノード数(適切を調査)\n",
    "n_hidden = 128\n",
    "\n",
    "# print(\"x before shape: {}\".format(sample_x.shape))\n",
    "\n",
    "# # flattenに入れる前の入力画像(特徴MAP)のサイズ確認\n",
    "conv1 = nn.Conv2d(3, 32, 3, padding=(1, 1))\n",
    "conv2 = nn.Conv2d(32, 32, 3, padding=(1, 1))\n",
    "conv3 = nn.Conv2d(32, 64, 3, padding=(1, 1))\n",
    "conv4 = nn.Conv2d(64, 64, 3, padding=(1, 1))\n",
    "conv5 = nn.Conv2d(64, 128, 3, padding=(1, 1))\n",
    "conv6 = nn.Conv2d(128, 128, 3, padding=(1, 1))\n",
    "\n",
    "bn1 = nn.BatchNorm2d(32)\n",
    "bn2 = nn.BatchNorm2d(32)\n",
    "bn3 = nn.BatchNorm2d(64)\n",
    "bn4 = nn.BatchNorm2d(64)\n",
    "bn5 = nn.BatchNorm2d(128)\n",
    "bn6 = nn.BatchNorm2d(128)\n",
    "\n",
    "dropout1 = nn.Dropout(0.2)\n",
    "dropout2 = nn.Dropout(0.3)\n",
    "dropout3 = nn.Dropout(0.4)\n",
    "\n",
    "relu = nn.ReLU(inplace=True)\n",
    "maxpool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "x1 = relu(bn1(conv1(sample_x)))\n",
    "x2 = dropout1(maxpool(relu(bn2(conv2(x1)))))\n",
    "x3 = relu(bn3(conv3(x2)))\n",
    "x4 = dropout2(maxpool(relu(bn4(conv4(x3)))))\n",
    "x5 = relu(bn5(conv5(x4)))\n",
    "x6 = dropout3(maxpool(relu(bn6(conv6(x5)))))\n",
    "\n",
    "x7 = torch.flatten(x6)\n",
    "print(\"x7 shape: {}\".format(x7.shape))\n",
    "\n",
    "# x2 = relu(x1)\n",
    "# x3 = conv2(x2)\n",
    "# x4 = relu(x3)\n",
    "# x5 = maxpool(x4)\n",
    "\n",
    "# print(\"x1 shape: {}\".format(x1.shape))\n",
    "# print(\"x2 shape: {}\".format(x2.shape))\n",
    "# print(\"x3 shape: {}\".format(x3.shape))\n",
    "# print(\"x4 shape: {}\".format(x4.shape))\n",
    "# print(\"x5 shape: {}\".format(x5.shape))\n",
    "\n",
    "# features = nn.Sequential(conv1, relu, conv2, relu, maxpool)\n",
    "\n",
    "# outputs = features(sample_x)\n",
    "# print(outputs)\n",
    "\n",
    "# flatten = nn.Flatten()\n",
    "# outputs2 = flatten(outputs)\n",
    "\n",
    "# print(\"outputs shape: {}\".format(outputs.shape))\n",
    "# print(\"outputs2 shape: {}\".format(outputs2.shape))\n",
    "\n",
    "\n",
    "# # flattenに入れる前の入力画像(特徴MAP)のサイズ確認\n",
    "# conv1 = nn.Conv2d(3, 32, 3)\n",
    "# conv2 = nn.Conv2d(32, 32, 3)\n",
    "# maxpool = nn.MaxPool2d((2, 2))\n",
    "# relu = nn.ReLU(inplace=True)\n",
    "\n",
    "# x = maxpool(relu(conv1(x)))\n",
    "# x = maxpool(relu(conv2(x)))\n",
    "# x = torch.flatten(x)\n",
    "\n",
    "# print(\"x shape: {}\".format(x.shape))\n",
    "\n",
    "\n",
    "input_size_into_FLATTEN = machine_learning_model.get_input_size_into_FLATTEN(sample_x)\n",
    "print(\"input_size_into_FLATTEN: {}\".format(input_size_into_FLATTEN))\n",
    "\n",
    "# load AlexNet\n",
    "net = machine_learning_model.AlexNet(n_output, n_hidden, sample_t).to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R868b0zHvl9L"
   },
   "outputs": [],
   "source": [
    "# 2.4 損失関数と最適化関数の定義\n",
    "\n",
    "const.lr = 0.01\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "# optimizer = optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用関数\n",
    "def fit(\n",
    "    net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history\n",
    "):\n",
    "    # tqdmライブラリのインポート\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    base_epochs = len(history)\n",
    "\n",
    "    for epoch in range(base_epochs, num_epochs + base_epochs):\n",
    "        # 1エポックあたりの正解数(精度計算用)\n",
    "        n_train_acc, n_val_acc = 0, 0\n",
    "        # 1エポックあたりの累積損失(平均化前)\n",
    "        train_loss, val_loss = 0, 0\n",
    "        # 1エポックあたりのデータ累積件数\n",
    "        n_train, n_test = 0, 0\n",
    "\n",
    "        # lossの最小値\n",
    "        min_val_loss = 1\n",
    "\n",
    "        # 訓練フェーズ\n",
    "        net.train()\n",
    "\n",
    "        # for inputs, labels in tqdm(train_loader):\n",
    "        for inputs, labels in train_loader:\n",
    "            # 1バッチあたりのデータ件数\n",
    "            train_batch_size = len(labels)\n",
    "            # 1エポックあたりのデータ累積件数\n",
    "            n_train += train_batch_size\n",
    "\n",
    "            # GPUヘ転送\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 勾配の初期化\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 予測計算\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # 損失計算\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 勾配計算\n",
    "            loss.backward()\n",
    "\n",
    "            # パラメータ修正\n",
    "            optimizer.step()\n",
    "\n",
    "            # 予測ラベル導出\n",
    "            predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "            # 平均前の損失と正解数の計算\n",
    "            # lossは平均計算が行われているので平均前の損失に戻して加算\n",
    "            train_loss += loss.item() * train_batch_size\n",
    "            n_train_acc += (predicted == labels).sum().item()\n",
    "\n",
    "        # 予測フェーズ\n",
    "        net.eval()\n",
    "\n",
    "        for inputs_test, labels_test in test_loader:\n",
    "            # 1バッチあたりのデータ件数\n",
    "            test_batch_size = len(labels_test)\n",
    "            # 1エポックあたりのデータ累積件数\n",
    "            n_test += test_batch_size\n",
    "\n",
    "            # GPUヘ転送\n",
    "            inputs_test = inputs_test.to(device)\n",
    "            labels_test = labels_test.to(device)\n",
    "\n",
    "            # 予測計算\n",
    "            outputs_test = net(inputs_test)\n",
    "\n",
    "            # 損失計算\n",
    "            loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "            # 予測ラベル導出\n",
    "            predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "            #  平均前の損失と正解数の計算\n",
    "            # lossは平均計算が行われているので平均前の損失に戻して加算\n",
    "            val_loss += loss_test.item() * test_batch_size\n",
    "            n_val_acc += (predicted_test == labels_test).sum().item()\n",
    "\n",
    "        # 精度計算\n",
    "        train_acc = n_train_acc / n_train\n",
    "        val_acc = n_val_acc / n_test\n",
    "        # 損失計算\n",
    "        avg_train_loss = train_loss / n_train\n",
    "        avg_val_loss = val_loss / n_test\n",
    "        # 結果表示\n",
    "        print(\n",
    "            f\"Epoch [{(epoch+1)}/{num_epochs+base_epochs}], loss: {avg_train_loss:.5f} acc: {train_acc:.5f} val_loss: {avg_val_loss:.5f}, val_acc: {val_acc:.5f}\"\n",
    "        )\n",
    "\n",
    "        # 記録\n",
    "        if min_val_loss > avg_val_loss:\n",
    "            torch.save(net.state_dict(), \"AlexNet_model_max_weight.pth\")\n",
    "\n",
    "        item = np.array([epoch + 1, avg_train_loss, train_acc, avg_val_loss, val_acc])\n",
    "        history = np.vstack((history, item))\n",
    "    return history\n",
    "\n",
    "\n",
    "history = np.zeros((0, 5))\n",
    "\n",
    "history = fit(\n",
    "    net,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    const.NUM_EPOCHS,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    device,\n",
    "    history,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ログ解析\n",
    "\n",
    "\n",
    "def evaluate_history(history):\n",
    "    # 損失と精度の確認\n",
    "    print(f\"初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}\")\n",
    "    print(f\"最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}\")\n",
    "\n",
    "    num_epochs = len(history)\n",
    "    unit = num_epochs / 10\n",
    "\n",
    "    # 学習曲線の表示 (損失)\n",
    "    plt.figure(figsize=(9, 8))\n",
    "    plt.plot(history[:, 0], history[:, 1], \"b\", label=\"訓練\")\n",
    "    plt.plot(history[:, 0], history[:, 3], \"k\", label=\"検証\")\n",
    "    plt.xticks(np.arange(0, num_epochs + 1, unit))\n",
    "    plt.xlabel(\"繰り返し回数\")\n",
    "    plt.ylabel(\"損失\")\n",
    "    plt.title(\"学習曲線(損失)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 学習曲線の表示 (精度)\n",
    "    plt.figure(figsize=(9, 8))\n",
    "    plt.plot(history[:, 0], history[:, 2], \"b\", label=\"訓練\")\n",
    "    plt.plot(history[:, 0], history[:, 4], \"k\", label=\"検証\")\n",
    "    plt.xticks(np.arange(0, num_epochs + 1, unit))\n",
    "    plt.xlabel(\"繰り返し回数\")\n",
    "    plt.ylabel(\"精度\")\n",
    "    plt.title(\"学習曲線(精度)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# イメージとラベル表示\n",
    "def show_images_labels(loader, classes, net, device):\n",
    "    # データローダーから最初の1セットを取得する\n",
    "    for images, labels in loader:\n",
    "        break\n",
    "    # 表示数は50個とバッチサイズのうち小さい方\n",
    "    n_size = min(len(images), 50)\n",
    "\n",
    "    if net is not None:\n",
    "        # デバイスの割り当て\n",
    "        inputs = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 予測計算\n",
    "        outputs = net(inputs)\n",
    "        predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 最初のn_size個の表示\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    for i in range(n_size):\n",
    "        ax = plt.subplot(5, 10, i + 1)\n",
    "        label_name = classes[labels[i]]\n",
    "        # netがNoneでない場合は、予測結果もタイトルに表示する\n",
    "        if net is not None:\n",
    "            predicted_name = classes[predicted[i]]\n",
    "            # 正解かどうかで色分けをする\n",
    "            if label_name == predicted_name:\n",
    "                c = \"k\"\n",
    "            else:\n",
    "                c = \"b\"\n",
    "            ax.set_title(label_name + \":\" + predicted_name, c=c, fontsize=20)\n",
    "        # netがNoneの場合は、正解ラベルのみ表示\n",
    "        else:\n",
    "            ax.set_title(label_name, fontsize=20)\n",
    "        # TensorをNumPyに変換\n",
    "        image_np = images[i].numpy().copy()\n",
    "        # 軸の順番変更 (channel, row, column) -> (row, column, channel)\n",
    "        img = np.transpose(image_np, (1, 2, 0))\n",
    "        # 値の範囲を[-1, 1] -> [0, 1]に戻す\n",
    "        img = (img + 1) / 2\n",
    "        # 結果表示\n",
    "        plt.imshow(img)\n",
    "        ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価\n",
    "\n",
    "evaluate_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初の50個の表示\n",
    "\n",
    "show_images_labels(test_loader, const.CLASSES, None, device)\n",
    "show_images_labels(test_loader, const.CLASSES, net, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
