{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_PATH = '/root'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import japanize_matplotlib\n",
    "from IPython.display import display\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "\n",
    "# Grad-CAM\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "from gradcam.utils import visualize_cam\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "# モデル\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()  else \"cpu\")\n",
    "\n",
    "n_output = 6\n",
    "n_hidden = 128\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self, n_output, n_hidden):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 32, 3, padding=(1,1))\n",
    "    self.conv2 = nn.Conv2d(32, 32, 3, padding=(1,1))\n",
    "    self.conv3 = nn.Conv2d(32, 64, 3, padding=(1,1))\n",
    "    self.conv4 = nn.Conv2d(64, 64, 3, padding=(1,1))\n",
    "    self.conv5 = nn.Conv2d(64, 128, 3, padding=(1,1))\n",
    "    self.conv6 = nn.Conv2d(128, 128, 3, padding=(1,1))\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.maxpool = nn.MaxPool2d((2,2))\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.l1 = nn.Linear(131072, n_hidden) # 256 v2\n",
    "\n",
    "    self.l2 = nn.Linear(n_hidden, n_output)\n",
    "    self.dropout1 = nn.Dropout(0.2)\n",
    "    self.dropout2 = nn.Dropout(0.3)\n",
    "    self.dropout3 = nn.Dropout(0.4)\n",
    "    self.bn1 = nn.BatchNorm2d(32)\n",
    "    self.bn2 = nn.BatchNorm2d(32)\n",
    "    self.bn3 = nn.BatchNorm2d(64)\n",
    "    self.bn4 = nn.BatchNorm2d(64)\n",
    "    self.bn5 = nn.BatchNorm2d(128)\n",
    "    self.bn6 = nn.BatchNorm2d(128)\n",
    "\n",
    "\n",
    "    self.features = nn.Sequential(\n",
    "        self.conv1,\n",
    "        self.bn1,\n",
    "        self.relu,\n",
    "        self.conv2,\n",
    "        self.bn2,\n",
    "        self.relu,\n",
    "        self.maxpool,\n",
    "        self.dropout1,\n",
    "        self.conv3,\n",
    "        self.bn3,\n",
    "        self.relu,\n",
    "        self.conv4,\n",
    "        self.bn4,\n",
    "        self.relu,\n",
    "        self.maxpool,\n",
    "        self.dropout2,\n",
    "        self.conv5,\n",
    "        self.bn5,\n",
    "        self.relu,\n",
    "        self.conv6,\n",
    "        self.bn6,\n",
    "        self.relu,\n",
    "        self.maxpool,\n",
    "        self.dropout3\n",
    "    )\n",
    "\n",
    "    self.classifier = nn.Sequential(\n",
    "        self.l1,\n",
    "        self.relu,\n",
    "        self.l2\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x1 = self.features(x)\n",
    "    x2 = self.flatten(x1)\n",
    "    x3 = self.classifier(x2)\n",
    "    return x3\n",
    "\n",
    "model = CNN(n_output, n_hidden)\n",
    "\n",
    "# print('summary')\n",
    "# summary(model, (3, 256, 256))\n",
    "\n",
    "filename = 'AlexNet_model_max_weight.pth'\n",
    "model.load_state_dict(torch.load(filename, map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "# Grad-CAMを計算するためのモデルを作成\n",
    "# print('model.features')\n",
    "# summary(model.features)\n",
    "# target_layer = model.features[-4]\n",
    "target_layer = model.features[0]\n",
    "\n",
    "gradcam = GradCAM(model, target_layer)\n",
    "\n",
    "# 画像を読み込み、前処理を適用\n",
    "datasets_npz_x1 = np.load(APP_PATH + '/dataset_npz/x.1_dataset/sc_x10_960_x1.npz')\n",
    "\n",
    "images = datasets_npz_x1['x']\n",
    "labels = datasets_npz_x1['y']\n",
    "\n",
    "image = images[10]\n",
    "dispaly_image = images[10]\n",
    "label = labels[10]\n",
    "\n",
    "image = Image.fromarray(image)\n",
    "image = image.convert(\"RGB\")\n",
    "image = image.resize((256, 256))\n",
    "image = np.asarray(image, np.float32)\n",
    "image = image.astype(float) / 255.0\n",
    "image = torch.from_numpy(image).float().permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "target_class = label\n",
    "\n",
    "# Grad-CAMの計算\n",
    "heatmap = gradcam(image, target_class)\n",
    "\n",
    "# ヒートマップを適切な形式に変換(正規化)\n",
    "heatmap = heatmap[0].squeeze().cpu().numpy()\n",
    "heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
    "heatmap = heatmap.astype(np.float32)\n",
    "heatmap = torch.from_numpy(heatmap)\n",
    "\n",
    "# 元の画像に可視化をオーバーレイ\n",
    "visualization = visualize_cam(heatmap, image)\n",
    "\n",
    "plt.imshow(dispaly_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "visualization_np = visualization[0][0].cpu().numpy()\n",
    "plt.imshow(visualization_np, cmap='jet')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# cv2.imwrite('gradcam_visualization.jpg', visualization)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
